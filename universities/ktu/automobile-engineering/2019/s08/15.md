---
country: "india"
university: "ktu"
branch: "automobile-engineering"
version: "2019"
semester: 8
course_code: "aut476"
course_title: "machine-learning"
language: "english"
contributor: "@UmarAlMukhtar"
---

# AUT476: Machine Learning

## Course Objectives

- Differentiate learning approaches and interpret supervised learning concepts.
- Interpret feature extraction and dimensionality reduction methods.
- Apply classification algorithms (Decision Trees, Linear Regression, SVM, Neural Networks, Bayes Classifier) to build models for real-world problems.
- Interpret the use of measures in evaluating classification models.
- Illustrate the use of Markov models in solving problems.
- Apply clustering algorithms and identify their applicability in real-life problems.

## Modules

### Module 1 — Introduction and Learning Paradigms

- Introduction to machine learning and overview of learning techniques.
- Learning associations; classification; regression; unsupervised learning; reinforcement learning.
- Supervised learning foundations: learning a class from examples; VC dimension; Probably Approximately Correct (PAC) learning; noise; learning multiple classes; model selection and generalization.

### Module 2 — Dimensionality Reduction and Bayesian/Regression Basics

- Dimensionality reduction: subset selection; Principal Component Analysis (PCA).
- Model validation: cross‑validation and resampling; k‑fold cross‑validation.
- Classifier performance: precision, recall, ROC curves.
- Bayes theorem; Bayesian classifier; maximum likelihood estimation (MLE).
- Regression: linear regression.

### Module 3 — Decision Trees and Neural Networks

- Decision trees: entropy; information gain; tree construction; ID3; issues in tree learning — avoiding overfitting; reduced‑error pruning; missing attributes; gain ratio.
- Neural networks: perceptron; activation functions; training feed‑forward networks via backpropagation.

### Module 4 — Kernel Machines and Markov Models

- Support Vector Machines (SVM): optimal separating hyperplane; soft‑margin hyperplane; kernel trick; kernel functions.
- Discrete Markov processes; Hidden Markov Models (HMMs): three basic problems — evaluation, decoding (state sequence), and learning parameters.

### Module 5 — Unsupervised Learning and Ensemble Methods

- Clustering: k‑means; Expectation‑Maximization (EM) algorithm; hierarchical clustering; density‑based clustering.
- Combining multiple learners: achieving diversity; model combination schemes; voting; bagging; boosting.

## References

- Ethem Alpaydin — Introduction to Machine Learning, MIT Press, 2004.
- Christopher M. Bishop — Pattern Recognition and Machine Learning, Springer, 2006.
- Margaret H. Dunham — Data Mining: Introductory and Advanced Topics, Pearson, 2006.
- Tom M. Mitchell — Machine Learning, McGraw‑Hill.
- R. S. Michalski, J. G. Carbonell, T. M. Mitchell (eds.) — Machine Learning: An Artificial Intelligence Approach, Tioga Publishing.
